{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa344c7",
   "metadata": {},
   "source": [
    "# MSADS509 Final Project M4 UE Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc06ad",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1f2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea09c89",
   "metadata": {},
   "source": [
    "## Scraping Political Data from CNN and Fox News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f5f662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/04/politics/us-dam...</td>\n",
       "      <td>US destroyed or damaged 84 of 85 targets in Ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/04/politics/nikki-...</td>\n",
       "      <td>Nikki Haley walks back comment that Texas can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/04/politics/china-...</td>\n",
       "      <td>Trump suggests he would consider a tariff upwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/04/politics/us-ret...</td>\n",
       "      <td>Sullivan vows ‘further action’ after US carrie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/03/politics/strike...</td>\n",
       "      <td>US, UK carry out series of strikes against Hou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                                url  \\\n",
       "0    cnn  https://www.cnn.com/2024/02/04/politics/us-dam...   \n",
       "2    cnn  https://www.cnn.com/2024/02/04/politics/nikki-...   \n",
       "3    cnn  https://www.cnn.com/2024/02/04/politics/china-...   \n",
       "4    cnn  https://www.cnn.com/2024/02/04/politics/us-ret...   \n",
       "5    cnn  https://www.cnn.com/2024/02/03/politics/strike...   \n",
       "\n",
       "                                             content  \n",
       "0  US destroyed or damaged 84 of 85 targets in Ir...  \n",
       "2  Nikki Haley walks back comment that Texas can ...  \n",
       "3  Trump suggests he would consider a tariff upwa...  \n",
       "4  Sullivan vows ‘further action’ after US carrie...  \n",
       "5  US, UK carry out series of strikes against Hou...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "source = {'cnn': \"https://www.cnn.com/politics\",\n",
    "          'foxnews': \"https://www.foxnews.com/politics\"}\n",
    "\n",
    "news_pages = defaultdict(list)  # Use a list to store URLs and content\n",
    "\n",
    "for source_name, source_page in source.items():\n",
    "    \n",
    "    # request the page and sleep\n",
    "    r = requests.get(source_page)\n",
    "    \n",
    "    time.sleep(5 + 10 * random.random())\n",
    "    \n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    links = soup.find_all('a', href=True)\n",
    "    \n",
    "    for link in links:\n",
    "        \n",
    "        href = link['href']\n",
    "        # Convert relative URLs to absolute URLs\n",
    "        full_url = urljoin(source_page, href)\n",
    "        \n",
    "        # Check if the link contains \"/politics/\" and does not contain \"/gallery/\"\n",
    "        if \"/politics/\" in full_url and \"/gallery/\" not in full_url:\n",
    "            \n",
    "            # Check if it's CNN and the URL has the format 'cnn.com/{}/'\n",
    "            if source_name == 'cnn' and f\"cnn.com/{current_year}/\" in full_url:\n",
    "                \n",
    "                # Fetch the news content\n",
    "                content_r = requests.get(full_url)\n",
    "                \n",
    "                content_soup = BeautifulSoup(content_r.content, 'html.parser')\n",
    "                \n",
    "                content = content_soup.get_text(separator=' ', strip=True)\n",
    "                \n",
    "                news_pages[source_name].append({'url': full_url, 'content': content})\n",
    "                \n",
    "            # Check if it's FOXNEWS and the URL does not contain \"/category/\"\n",
    "            elif source_name == 'foxnews' and \"/category/\" not in full_url:\n",
    "                \n",
    "                # Fetch the news content\n",
    "                content_r = requests.get(full_url)\n",
    "                \n",
    "                content_soup = BeautifulSoup(content_r.content, 'html.parser')\n",
    "                \n",
    "                content = content_soup.get_text(separator=' ', strip=True)\n",
    "                \n",
    "                news_pages[source_name].append({'url': full_url, 'content': content})\n",
    "\n",
    "# Create a DataFrame\n",
    "\n",
    "df = pd.DataFrame([(source_name, item['url'], item['content']) for source_name, items in \n",
    "                   news_pages.items() for item in items], columns=['source', 'url', 'content'])\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f62f4",
   "metadata": {},
   "source": [
    "## News Counts for CNN and Fox News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5926e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN rows: 47\n",
      "Fox News rows: 21\n"
     ]
    }
   ],
   "source": [
    "source_counts = df['source'].value_counts()\n",
    "\n",
    "# Print the counts for each source\n",
    "print(\"CNN rows:\", source_counts.get('cnn', 0))\n",
    "print(\"Fox News rows:\", source_counts.get('foxnews', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412f06d",
   "metadata": {},
   "source": [
    "## Saving Results to Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a2db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/UE/Desktop/MSADS509_news_project.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
